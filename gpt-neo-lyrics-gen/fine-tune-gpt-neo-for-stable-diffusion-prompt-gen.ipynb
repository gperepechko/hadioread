{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Generating Radiohead lyrics with GPT-Neo\n","**by gperepechko** "]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-03-08T16:31:01.547948Z","iopub.status.busy":"2023-03-08T16:31:01.547575Z","iopub.status.idle":"2023-03-08T16:31:02.558789Z","shell.execute_reply":"2023-03-08T16:31:02.557563Z","shell.execute_reply.started":"2023-03-08T16:31:01.547871Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Wed Mar  8 16:31:02 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.82.01    Driver Version: 470.82.01    CUDA Version: 11.4     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   30C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","!nvidia-smi"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-03-08T16:31:29.734507Z","iopub.status.busy":"2023-03-08T16:31:29.734111Z","iopub.status.idle":"2023-03-08T16:31:40.956729Z","shell.execute_reply":"2023-03-08T16:31:40.955735Z","shell.execute_reply.started":"2023-03-08T16:31:29.734470Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a81ff3b8e6da49779979327f08c08287","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/4.08k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Downloading and preparing dataset lyrics_dataset/default to /root/.cache/huggingface/datasets/huggingartists___lyrics_dataset/default/1.0.0/d37c36412fe443a2baba285a9d3ab4e8e4df79db8feb93b2f775c3dacfeca9eb...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c041b882ae1f47efae91c084dee4cb91","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/276k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Dataset lyrics_dataset downloaded and prepared to /root/.cache/huggingface/datasets/huggingartists___lyrics_dataset/default/1.0.0/d37c36412fe443a2baba285a9d3ab4e8e4df79db8feb93b2f775c3dacfeca9eb. Subsequent calls will reuse this data.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8830947c43154c7791f11d126f8d5731","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from datasets import load_dataset\n","dataset = load_dataset(\"huggingartists/radiohead\")"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-03-08T16:32:59.314768Z","iopub.status.busy":"2023-03-08T16:32:59.314378Z","iopub.status.idle":"2023-03-08T16:32:59.321715Z","shell.execute_reply":"2023-03-08T16:32:59.320433Z","shell.execute_reply.started":"2023-03-08T16:32:59.314734Z"},"trusted":true},"outputs":[],"source":["text = ['<|endoftext|>']\n","for t in dataset['train']['text']:\n","    text += t.split('\\n')\n","    text.append('<|endoftext|>')"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-03-08T16:36:51.586749Z","iopub.status.busy":"2023-03-08T16:36:51.586344Z","iopub.status.idle":"2023-03-08T16:36:51.630327Z","shell.execute_reply":"2023-03-08T16:36:51.629420Z","shell.execute_reply.started":"2023-03-08T16:36:51.586711Z"},"trusted":true},"outputs":[],"source":["with open('data.txt', 'w') as f:\n","    f.writelines('\\n'.join(text))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Loading Model "]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-03-08T16:33:31.323290Z","iopub.status.busy":"2023-03-08T16:33:31.322589Z","iopub.status.idle":"2023-03-08T16:33:46.491889Z","shell.execute_reply":"2023-03-08T16:33:46.490652Z","shell.execute_reply.started":"2023-03-08T16:33:31.323253Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["! pip install aitextgen -q"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-03-08T16:34:40.029493Z","iopub.status.busy":"2023-03-08T16:34:40.029094Z","iopub.status.idle":"2023-03-08T16:34:40.034798Z","shell.execute_reply":"2023-03-08T16:34:40.033723Z","shell.execute_reply.started":"2023-03-08T16:34:40.029456Z"},"trusted":true},"outputs":[],"source":["model=\"EleutherAI/gpt-neo-125M\""]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-03-08T16:34:48.821912Z","iopub.status.busy":"2023-03-08T16:34:48.821447Z","iopub.status.idle":"2023-03-08T16:34:56.570419Z","shell.execute_reply":"2023-03-08T16:34:56.569340Z","shell.execute_reply.started":"2023-03-08T16:34:48.821871Z"},"trusted":true},"outputs":[],"source":["from aitextgen.TokenDataset import TokenDataset"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-03-08T16:35:13.740166Z","iopub.status.busy":"2023-03-08T16:35:13.739794Z","iopub.status.idle":"2023-03-08T16:35:13.746418Z","shell.execute_reply":"2023-03-08T16:35:13.744686Z","shell.execute_reply.started":"2023-03-08T16:35:13.740133Z"},"trusted":true},"outputs":[],"source":["from aitextgen import aitextgen"]},{"cell_type":"code","execution_count":74,"metadata":{"execution":{"iopub.execute_input":"2023-03-08T16:55:10.136816Z","iopub.status.busy":"2023-03-08T16:55:10.136416Z","iopub.status.idle":"2023-03-08T16:55:23.370477Z","shell.execute_reply":"2023-03-08T16:55:23.369110Z","shell.execute_reply.started":"2023-03-08T16:55:10.136781Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["loading file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/vocab.json from cache at aitextgen/08c00c4159e921d4c941ac75732643373aba509d9b352a82bbbb043a94058d98.a552555fdda56a1c7c9a285bccfd44ac8e4b9e26c8c9b307831b3ea3ac782b45\n","loading file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/merges.txt from cache at aitextgen/12305762709d884a770efe7b0c68a7f4bc918da44e956058d43da0d12f7bea20.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n","loading file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/tokenizer.json from cache at None\n","loading file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/special_tokens_map.json from cache at aitextgen/6c3239a63aaf46ec7625b38abfe41fc2ce0b25f90800aefe6526256340d4ab6d.2b8bf81243d08385c806171bc7ced6d2a0dcc7f896ca637f4e777418f7f0cc3c\n","loading file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/tokenizer_config.json from cache at aitextgen/3cc88b3aa29bb2546db2dc21783292e2a086bb7158c7b5ceddeb24158a85c183.e74f7c3643ee79eb023ead36008be72fe726dada60fa3b2a0569925cfefa1e74\n"]}],"source":["# ai = aitextgen(tf_gpt2=\"124M\",  to_gpu=True)\n","ai = aitextgen(model = model,  to_gpu=True)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Model Finetuning"]},{"cell_type":"code","execution_count":93,"metadata":{"execution":{"iopub.execute_input":"2023-03-08T16:58:05.202774Z","iopub.status.busy":"2023-03-08T16:58:05.202370Z","iopub.status.idle":"2023-03-08T16:58:57.555427Z","shell.execute_reply":"2023-03-08T16:58:57.554028Z","shell.execute_reply.started":"2023-03-08T16:58:05.202738Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6d159d810cee483799276786322723cd","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/10537 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:448: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n","  f\"Setting `Trainer(gpus={gpus!r})` is deprecated in v1.7 and will be removed\"\n"]},{"name":"stdout","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/configuration_validator.py:259: LightningDeprecationWarning: The `Callback.on_batch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_end` instead.\n","  f\"The `Callback.{hook}` hook was deprecated in v1.6 and\"\n"]},{"name":"stdout","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cc995d95c4784348b8d98c72f1663bd8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/100 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","\u001b[1m100 steps reached: generating sample texts.\u001b[0m\n","==========\n","\n","==========\n"]}],"source":["ai.train('data.txt',\n","         line_by_line=True,\n","         from_cache=False,\n","         num_steps=100,\n","         generate_every=100,\n","         save_every=500,\n","         save_gdrive=False,\n","         learning_rate=1e-3,\n","         fp16=False,\n","         batch_size=1, \n","         )"]},{"cell_type":"code","execution_count":94,"metadata":{"execution":{"iopub.execute_input":"2023-03-08T16:58:57.559147Z","iopub.status.busy":"2023-03-08T16:58:57.558390Z","iopub.status.idle":"2023-03-08T16:58:58.653467Z","shell.execute_reply":"2023-03-08T16:58:58.652298Z","shell.execute_reply.started":"2023-03-08T16:58:57.559098Z"},"trusted":true},"outputs":[],"source":["ai.save()\n"]},{"cell_type":"code","execution_count":95,"metadata":{"execution":{"iopub.execute_input":"2023-03-08T16:59:00.235571Z","iopub.status.busy":"2023-03-08T16:59:00.235206Z","iopub.status.idle":"2023-03-08T16:59:03.360751Z","shell.execute_reply":"2023-03-08T16:59:03.359731Z","shell.execute_reply.started":"2023-03-08T16:59:00.235536Z"},"trusted":true},"outputs":[],"source":["prompt_ai = aitextgen(model_folder = '.', to_gpu=True)"]},{"cell_type":"code","execution_count":96,"metadata":{"execution":{"iopub.execute_input":"2023-03-08T16:59:07.623474Z","iopub.status.busy":"2023-03-08T16:59:07.623096Z","iopub.status.idle":"2023-03-08T16:59:07.748946Z","shell.execute_reply":"2023-03-08T16:59:07.747156Z","shell.execute_reply.started":"2023-03-08T16:59:07.623441Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["myself, my spirit\n","\n"]}],"source":["print(prompt_ai.generate_one(prompt = \"\"))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## New Lyrics Generating"]},{"cell_type":"code","execution_count":108,"metadata":{"execution":{"iopub.execute_input":"2023-03-08T17:00:46.541427Z","iopub.status.busy":"2023-03-08T17:00:46.541045Z","iopub.status.idle":"2023-03-08T17:00:46.855384Z","shell.execute_reply":"2023-03-08T17:00:46.854387Z","shell.execute_reply.started":"2023-03-08T17:00:46.541393Z"},"trusted":true},"outputs":[{"data":{"text/plain":["['!\\n',\n"," 'myself\\n',\n"," 'doors and there were doors thatCouldve loved me and I was like them. My niece and dad werent they friends\\n',\n"," 'Its not like the movies but we all like the movies\\n',\n"," 'get to the chorus\\n',\n"," 'stars arent stars but theyreWait\\n',\n"," 'special\\n',\n"," 'get over, over, over\\n',\n"," 'doors and there are doors themselves\\n',\n"," 'Ive been around\\n',\n"," 'Im living in a business while\\n',\n"," 'Im so lost from work\\n',\n"," 'wish that something\\n',\n"," 'come back again\\n',\n"," 'myself\\n',\n"," 'Whose I?\\n',\n"," 'Its always so near\\n',\n"," 'and I will not walk\\n',\n"," 'I’ll Wear It\\n',\n"," 'Whats that?\\n',\n"," 'ahead of me\\n',\n"," 'Its not so clever\\n',\n"," 'here\\n',\n"," 'Im gonna...\\n',\n"," 'Im hungry for the goodies, boys and girls\\n',\n"," 'myself, myself\\n',\n"," 'Its so so so so so near\\n',\n"," 'can\\n',\n"," 'myself, babe\\n']"]},"execution_count":108,"metadata":{},"output_type":"execute_result"}],"source":["prompt_ai.generate(n=100, temperature=0.9, return_as_list=True)"]},{"cell_type":"code","execution_count":162,"metadata":{"execution":{"iopub.execute_input":"2023-03-08T17:12:55.315822Z","iopub.status.busy":"2023-03-08T17:12:55.315407Z","iopub.status.idle":"2023-03-08T17:12:55.320396Z","shell.execute_reply":"2023-03-08T17:12:55.319414Z","shell.execute_reply.started":"2023-03-08T17:12:55.315783Z"},"trusted":true},"outputs":[],"source":["outs = []"]},{"cell_type":"code","execution_count":109,"metadata":{"execution":{"iopub.execute_input":"2023-03-08T17:01:39.600065Z","iopub.status.busy":"2023-03-08T17:01:39.599551Z","iopub.status.idle":"2023-03-08T17:01:39.607759Z","shell.execute_reply":"2023-03-08T17:01:39.606707Z","shell.execute_reply.started":"2023-03-08T17:01:39.600024Z"},"trusted":true},"outputs":[],"source":["from tqdm import trange"]},{"cell_type":"code","execution_count":166,"metadata":{"execution":{"iopub.execute_input":"2023-03-08T17:13:45.466236Z","iopub.status.busy":"2023-03-08T17:13:45.465862Z","iopub.status.idle":"2023-03-08T17:13:48.711480Z","shell.execute_reply":"2023-03-08T17:13:48.710367Z","shell.execute_reply.started":"2023-03-08T17:13:45.466204Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 10/10 [00:03<00:00,  3.09it/s]\n"]}],"source":["for i in trange(10):\n","    lines = prompt_ai.generate(n=100, temperature=0.9, return_as_list=True, min_length=6, max_length=50)\n","    for line in lines:\n","        if not line or not line[0].isalnum() or len(line) < 3:\n","            continue\n","        outs.append(line[0].upper() + str(line[1:]))"]},{"cell_type":"code","execution_count":168,"metadata":{"execution":{"iopub.execute_input":"2023-03-08T17:14:22.005822Z","iopub.status.busy":"2023-03-08T17:14:22.005233Z","iopub.status.idle":"2023-03-08T17:14:22.025083Z","shell.execute_reply":"2023-03-08T17:14:22.024173Z","shell.execute_reply.started":"2023-03-08T17:14:22.005771Z"},"trusted":true},"outputs":[],"source":["with open('predicts.txt', 'w') as f:\n","    f.writelines('\\n'.join(outs))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12 (main, Mar 26 2022, 15:52:10) \n[Clang 13.0.0 (clang-1300.0.29.30)]"},"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}},"nbformat":4,"nbformat_minor":4}
